{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://kdd.ics.uci.edu/databases/kddcup99/training_attack_types\n",
    "# Attack name and type\n",
    "data = '''back dos\n",
    "buffer_overflow u2r\n",
    "ftp_write r2l\n",
    "guess_passwd r2l\n",
    "imap r2l\n",
    "ipsweep probe\n",
    "land dos\n",
    "loadmodule u2r\n",
    "multihop r2l\n",
    "neptune dos\n",
    "nmap probe\n",
    "perl u2r\n",
    "phf r2l\n",
    "pod dos\n",
    "portsweep probe\n",
    "rootkit u2r\n",
    "satan probe\n",
    "smurf dos\n",
    "spy r2l\n",
    "teardrop dos\n",
    "warezclient r2l\n",
    "warezmaster r2l'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attack group types: dos, probe, r2l, u2r\n",
      "\n",
      "type\n",
      "dos            [back, land, neptune, pod, smurf, teardrop]\n",
      "probe                    [ipsweep, nmap, portsweep, satan]\n",
      "r2l      [ftp_write, guess_passwd, imap, multihop, phf,...\n",
      "u2r           [buffer_overflow, loadmodule, perl, rootkit]\n",
      "Name: name, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# grouped by type\n",
    "attack_types = pd.DataFrame([row.split() for row in data.split('\\n')], columns=['name','type'])\n",
    "attack_type_groups = attack_types.groupby('type')['name'].unique()\n",
    "\n",
    "print('attack group types: {}'.format(', '.join(attack_type_groups.index)))\n",
    "print()\n",
    "print(attack_type_groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "X, y = fetch_openml(data_id='1113', return_X_y=True, as_frame=True)\n",
    "print('n records: {}'.format(len(X.index)))\n",
    "X_preserved = X.copy()\n",
    "y_preserved = y.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run as an alternative to the above, as needed\n",
    "#X = X_preserved.copy()\n",
    "#y = y_preserved.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_attack_type_downsampled_balanced_subset(attack_names, label, X, y):\n",
    "    print('Attack group name: {}'.format(label))\n",
    "    print('Attack_types: {}'.format(', '.join(attack_names)))\n",
    "    \n",
    "    is_type_attack = y.isin(attack_names)\n",
    "    \n",
    "    only_attack_type = y[is_type_attack]\n",
    "    only_not_attack_type = y[~is_type_attack]\n",
    "    \n",
    "    only_attack_type = is_type_attack[is_type_attack]\n",
    "    only_not_attack_type = is_type_attack[~is_type_attack]\n",
    "    \n",
    "    \n",
    "    num_attack_type = only_attack_type.shape[0]\n",
    "    num_not_attack_type = only_not_attack_type.shape[0]\n",
    "    \n",
    "    print('Num attack type: {}'.format(num_attack_type))\n",
    "    print('Num not attack type: {}'.format(num_not_attack_type))\n",
    "    \n",
    "\n",
    "    # Take a balanced sample\n",
    "    # which one has less? that is the one we should downsample\n",
    "    lowest_count = min(num_attack_type, num_not_attack_type)\n",
    "    \n",
    "    balanced_ys = []\n",
    "    balanced_Xs = []\n",
    "    for subset_y in [only_attack_type, only_not_attack_type]:\n",
    "        _subset_y = subset_y.copy()\n",
    "        if _subset_y.shape[0] > lowest_count:\n",
    "            _subset_y = subset_y.sample(n=lowest_count)\n",
    "        subset_X = X.loc[_subset_y.index, :]\n",
    "        balanced_Xs.append(subset_X)\n",
    "        balanced_ys.append(_subset_y)\n",
    "    \n",
    "    assert len(balanced_Xs) == len(balanced_ys)\n",
    "    \n",
    "    for i, balanced_y in enumerate(balanced_ys):\n",
    "        assert balanced_y.shape[0] == lowest_count\n",
    "        assert balanced_Xs[i].shape[0] == lowest_count\n",
    "        \n",
    "    X_new = pd.concat(balanced_Xs)\n",
    "    y_new = pd.concat(balanced_ys).rename(label)\n",
    "    \n",
    "    print(X_new.shape[0])\n",
    "    print(y_new.shape[0])\n",
    "    print()\n",
    "    \n",
    "    return X_new, y_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_is_dos, y_is_dos = get_attack_type_downsampled_balanced_subset(attack_type_groups['dos'], 'is_dos_attack', X, y)\n",
    "X_is_probe, y_is_probe = get_attack_type_downsampled_balanced_subset(attack_type_groups['probe'], 'is_probe_attack', X, y)\n",
    "X_is_r2l, y_is_r2l = get_attack_type_downsampled_balanced_subset(attack_type_groups['r2l'], 'is_r2l_attack', X, y)\n",
    "X_is_u2r, y_is_u2r = get_attack_type_downsampled_balanced_subset(attack_type_groups['u2r'], 'is_u2r_attack', X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Which one to run the following analyses on? Options are the pairs generated in the cell above\n",
    "X, y = X_is_probe, y_is_probe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://scikit-learn.org/stable/auto_examples/compose/plot_column_transformer_mixed_types.html\n",
    "# https://scikit-learn.org/stable/auto_examples/classification/plot_classifier_comparison.html\n",
    "# https://www.kaggle.com/gautham11/building-a-scikit-learn-classification-pipeline\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.linear_model import LogisticRegression, RidgeClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "# We create the preprocessing pipelines for both numeric and categorical data.\n",
    "#numeric_features = ['duration']\n",
    "numeric_features = ['src_bytes','dst_bytes']\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())])\n",
    "\n",
    "categorical_features = ['protocol_type']\n",
    "#categorical_features = []\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://scikit-learn.org/stable/auto_examples/model_selection/plot_precision_recall.html#sphx-glr-auto-examples-model-selection-plot-precision-recall-py\n",
    "# https://scikit-learn.org/stable/auto_examples/model_selection/plot_roc.html\n",
    "# [plot ROC curve sklearn](https://stackoverflow.com/a/47562197/5917194)\n",
    "# [Precision-recall AUC](https://machinelearningmastery.com/roc-curves-and-precision-recall-curves-for-imbalanced-classification/)\n",
    "# [Average precision and AUC precision-recall](https://scikit-learn.org/stable/auto_examples/model_selection/plot_precision_recall.html#sphx-glr-auto-examples-model-selection-plot-precision-recall-py)\n",
    "\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import plot_precision_recall_curve\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Append classifier to preprocessing pipeline.\n",
    "# Now we have a full prediction pipeline.\n",
    "classifiers = [\n",
    "    LogisticRegression(),\n",
    "    #DecisionTreeClassifier(),\n",
    "    RandomForestClassifier(),\n",
    "    GaussianNB()\n",
    "    #MLPClassifier()\n",
    "    #KNeighborsClassifier()\n",
    "]\n",
    "\n",
    "clf = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                      ('clf', None)])\n",
    "\n",
    "# [introduction pyplot tutorial](https://matplotlib.org/tutorials/introductory/pyplot.html)\n",
    "# [separate figures](https://matplotlib.org/tutorials/intermediate/artists.html)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "roc_things = []\n",
    "precision_recall_things = []\n",
    "\n",
    "for classifier in classifiers:\n",
    "    clf.set_params(clf=classifier).fit(X_train, y_train)\n",
    "    classifier_name = classifier.__class__.__name__\n",
    "    print(str(classifier))\n",
    "    print(\"model score: %.3f\" % clf.score(X_test, y_test))\n",
    "    \n",
    "    \n",
    "    y_score = clf.predict_proba(X_test)[:,1]\n",
    "    \n",
    "    roc_auc = roc_auc_score(y_test, y_score)\n",
    "    fpr, tpr, _ = roc_curve(y_test, y_score)\n",
    "    roc_things.append((fpr, tpr, '{} AUC: {:.3f}'.format(classifier_name, roc_auc)))\n",
    "    \n",
    "    precision, recall, thresholds = precision_recall_curve(y_test, y_score)\n",
    "    pr_auc = auc(recall, precision)\n",
    "    precision_recall_things.append((recall, precision, thresholds, '{} AUC: {:.3f}'.format(classifier_name, pr_auc)))\n",
    "    #plot_precision_recall_curve(clf, X_test, y_test)\n",
    "    \n",
    "    print('average precision score: {:.3f}'.format(average_precision_score(y_test, y_score)))\n",
    "    print('roc_auc_score: {:.3f}'.format(roc_auc))\n",
    "    print('precision-recall AUC: {:.3f}'.format(pr_auc))\n",
    "    print()\n",
    "\n",
    "roc_plt = plt.figure()\n",
    "lw = 4\n",
    "for roc_thing in roc_things:\n",
    "    fpr, tpr, label = roc_thing\n",
    "    plt.plot(fpr, tpr, lw=lw, label=label)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--') # dadgum no-skill line\n",
    "plt.legend()\n",
    "plt.title('ROC curve')\n",
    "          \n",
    "pr_plt = plt.figure()\n",
    "for pr_thing in precision_recall_things:\n",
    "    recall, precision, _, label = pr_thing\n",
    "    plt.plot(recall, precision, lw=lw, label=label)\n",
    "ratio = y_test[y_test].shape[0] / y_test.shape[0]\n",
    "plt.hlines(y=ratio, xmin=0, xmax=1, color='navy', lw=lw, linestyle='--') # dadgum no-skill line\n",
    "plt.title('Precision-recall plot')\n",
    "plt.legend()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best was random forest...\n",
    "from scipy.stats import hmean\n",
    "import numpy.ma as ma\n",
    "\n",
    "recall, precision, thresholds, _ = precision_recall_things[1] # random forest\n",
    "\n",
    "# make a 2D numpy array out of our recall and precision values\n",
    "a = np.column_stack((recall,precision))\n",
    "\n",
    "# harmonic mean is only valid for values greater than 0.\n",
    "# \"mask\" out any rows with values less than or equal to 0\n",
    "# https://docs.scipy.org/doc/numpy/reference/maskedarray.generic.html\n",
    "# https://docs.scipy.org/doc/numpy/reference/generated/numpy.ma.mask_rows.html\n",
    "a = ma.masked_less_equal(a, 0)\n",
    "a = ma.mask_rows(a)\n",
    "f1 = hmean(a,axis=1)\n",
    "\n",
    "# np.argmax returns the index of the largest value in an array. This will map to the threshold array that\n",
    "# was associated with the precision and recall which generated that \"best F1 score\"\n",
    "# I'm sure there's a better way to do the above, but IDK I'm a noob\n",
    "threshold_that_maximizes_f1 = thresholds[np.argmax(f1)]\n",
    "print('threshold that optimizes f1: {}'.format(threshold_that_maximizes_f1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
